{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jpgAfFjOQnZf",
    "outputId": "6c77e197-3162-4ceb-ea02-6b9d4003d074",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:23:05.951466Z",
     "start_time": "2025-10-26T06:22:56.510837Z"
    }
   },
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(0)"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2936d979d10>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "nNxHN5Ffe4lI",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:24:00.914540Z",
     "start_time": "2025-10-26T06:24:00.907515Z"
    }
   },
   "source": [
    "with open('AeCa.txt', 'r', encoding='UTF-8') as f:\n",
    "    text=f.read()\n",
    "f.close()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eEfAtaGRfFTT",
    "outputId": "3964d3d3-fe75-4f0b-e409-148db202992a",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:24:03.579193Z",
     "start_time": "2025-10-26T06:24:03.565738Z"
    }
   },
   "source": [
    "chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)\n",
    "print(chars,vocab_size)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'G', 'T'] 4\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wd-5SQ47fT5M",
    "outputId": "8dc0fd22-95ba-4dea-a0ce-ba505f5fd5f4",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:24:05.763121Z",
     "start_time": "2025-10-26T06:24:05.756485Z"
    }
   },
   "source": [
    "stoi={s:i for i,s in enumerate(chars)}\n",
    "itos={i:s for i,s in enumerate(stoi)}\n",
    "stoi,itos"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'A': 0, 'C': 1, 'G': 2, 'T': 3}, {0: 'A', 1: 'C', 2: 'G', 3: 'T'})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ao9WvW9fVh4",
    "outputId": "14f71aad-9075-46d3-d2c0-403363a5c723",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:24:06.502238Z",
     "start_time": "2025-10-26T06:24:06.296865Z"
    }
   },
   "source": [
    "encode=lambda word:[stoi[s] for s in word]\n",
    "decode=lambda num: ''.join([itos[i] for i in num])\n",
    "data=torch.tensor(encode(text),dtype=torch.long)\n",
    "data"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1,  ..., 2, 2, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JKVRgeelhm9p",
    "outputId": "b79b3117-b7f2-480b-82c6-4aca044ae751",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:24:07.893352Z",
     "start_time": "2025-10-26T06:24:07.886803Z"
    }
   },
   "source": [
    "data[0]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ul69G6Jnf6wx",
    "outputId": "bf63da92-d0be-4903-fc0b-b9588750e050",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:24:23.423943Z",
     "start_time": "2025-10-26T06:24:10.174483Z"
    }
   },
   "source": [
    "def cut_sequence(data, window_size):\n",
    "  X,Y = [],[]\n",
    "  for i in range(0,len(data)-window_size):\n",
    "    X.append(data[i:i+window_size])\n",
    "    Y.append(data[i+window_size])\n",
    "  return X,Y\n",
    "\n",
    "window_size = 64\n",
    "X_list, Y_list = cut_sequence(data, window_size)\n",
    "\n",
    "X = torch.stack(X_list)\n",
    "Y = torch.tensor(Y_list)\n",
    "\n",
    "print(X.shape)\n",
    "print(Y.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1590985, 64])\n",
      "torch.Size([1590985])\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "MjCORBjyijpe",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:24:28.007013Z",
     "start_time": "2025-10-26T06:24:28.001486Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "\n",
    "one_hot_mapping = {\n",
    "    0:[1,0,0,0],\n",
    "    1:[0,1,0,0],\n",
    "    2:[0,0,1,0],\n",
    "    3:[0,0,0,1]\n",
    "}\n",
    "def OneHot(arr,one_hot_mapping):\n",
    "  if arr.ndim == 2:\n",
    "    result = np.array([[one_hot_mapping[val.item()] for val in row] for row in arr])\n",
    "    return result\n",
    "  else:\n",
    "    result = np.array([one_hot_mapping[val.item()] for val in arr])\n",
    "    return result"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-10-26T06:33:09.553276Z",
     "start_time": "2025-10-26T06:33:09.547675Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "\n",
    "def optimized_OneHot(arr, one_hot_mapping):\n",
    "  output_dim = len(one_hot_mapping[0])\n",
    "  flat_arr = arr.flatten()\n",
    "  one_hot = np.zeros((flat_arr.size, output_dim), dtype=np.float32)\n",
    "  one_hot[np.arange(flat_arr.size), flat_arr] = 1\n",
    "  if arr.ndim == 2:\n",
    "    return one_hot.reshape((*arr.shape, output_dim))\n",
    "  else:\n",
    "    return one_hot"
   ],
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "K3iUNIFrloUS",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:34:36.268202Z",
     "start_time": "2025-10-26T06:34:34.275764Z"
    }
   },
   "source": [
    "X = torch.tensor(optimized_OneHot(X.numpy(),one_hot_mapping))\n",
    "Y = torch.tensor(optimized_OneHot(Y.numpy(),one_hot_mapping))"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sEv_KR2vlriT",
    "outputId": "7606bd2e-a079-4e09-9f05-8f4710e62f56",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:34:38.967797Z",
     "start_time": "2025-10-26T06:34:38.963800Z"
    }
   },
   "source": [
    "print(X.shape)\n",
    "print(Y.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1590985, 64, 4])\n",
      "torch.Size([1590985, 4])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "xvuZHFAe-AJY",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:34:56.418909Z",
     "start_time": "2025-10-26T06:34:56.411522Z"
    }
   },
   "source": [
    "import torch.nn.functional as F\n",
    "class DNACoder(nn.Module):\n",
    "    def __init__(self, input_dim=4, window_size=64, hidden_dim=256, num_heads=8, fc_dim=128):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv1d(in_channels=input_dim, out_channels=64, kernel_size=3)\n",
    "        self.bn1 = nn.BatchNorm1d(num_features=64)\n",
    "        self.pool1 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm1d(num_features=128)\n",
    "        self.pool2 = nn.MaxPool1d(kernel_size=2)\n",
    "\n",
    "        self.lstm = nn.LSTM(input_size=128, hidden_size=hidden_dim, batch_first=True, bidirectional=True)\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=hidden_dim*2, num_heads=num_heads, batch_first=True)\n",
    "\n",
    "        self.dropout = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(hidden_dim*2, fc_dim)\n",
    "        self.fc_out = nn.Linear(fc_dim, 4)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.permute(0, 2, 1)  # (B, 4, seq_len)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool2(x)\n",
    "        x = x.permute(0, 2, 1)  # (B, seq_len, 128)\n",
    "\n",
    "        lstm_out, _ = self.lstm(x)\n",
    "        attn_out, _ = self.attn(lstm_out, lstm_out, lstm_out)\n",
    "        x = self.dropout(F.relu(self.fc1(attn_out[:, -1, :])))\n",
    "        out = self.fc_out(x)\n",
    "        return out\n"
   ],
   "outputs": [],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "WM7yn81IZcq4",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:34:58.436954Z",
     "start_time": "2025-10-26T06:34:58.414977Z"
    }
   },
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "dataset = TensorDataset(X, Y.argmax(dim=1))\n",
    "\n",
    "# Create a DataLoader (loads in small batches)\n",
    "loader = DataLoader(dataset, batch_size=256, shuffle=True, pin_memory=True)"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "49BALJXObWda",
    "outputId": "0bb73b3b-3521-4f41-a609-29f58d178cc6",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:35:00.334194Z",
     "start_time": "2025-10-26T06:35:00.182732Z"
    }
   },
   "source": [
    "for xb, yb in loader:\n",
    "    print(xb.shape)\n",
    "    print(yb.shape)\n",
    "    break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 64, 4])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a1eQqBFJb_wU",
    "outputId": "ece6aaab-d32f-4acb-8463-594edca47b5f",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:35:02.883452Z",
     "start_time": "2025-10-26T06:35:02.590696Z"
    }
   },
   "source": [
    "#Just testing for my convenience\n",
    "model = DNACoder(input_dim=4, window_size=window_size)\n",
    "outputs = model(xb.float())\n",
    "print(outputs.shape)\n",
    "print(outputs)\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "preds = torch.argmax(outputs, dim=1)\n",
    "print(preds.shape)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([256, 4])\n",
      "tensor([[ 0.0501,  0.0093,  0.0207, -0.0636],\n",
      "        [ 0.0664, -0.0013,  0.0329, -0.0765],\n",
      "        [ 0.0625,  0.0025,  0.0222, -0.0670],\n",
      "        ...,\n",
      "        [ 0.0497, -0.0208,  0.0086, -0.0436],\n",
      "        [ 0.0487, -0.0303,  0.0391, -0.0576],\n",
      "        [ 0.0688, -0.0139,  0.0259, -0.0668]], grad_fn=<AddmmBackward0>)\n",
      "torch.Size([256])\n",
      "tensor([2, 1, 3, 2, 1, 1, 2, 0, 0, 1, 2, 2, 2, 2, 0, 1, 1, 0, 1, 1, 3, 2, 3, 1,\n",
      "        2, 3, 2, 1, 1, 1, 3, 1, 3, 2, 3, 0, 3, 2, 3, 2, 1, 3, 1, 2, 1, 2, 0, 0,\n",
      "        0, 3, 1, 2, 0, 1, 3, 2, 1, 1, 0, 2, 1, 2, 2, 1, 1, 1, 2, 0, 1, 2, 2, 0,\n",
      "        2, 3, 0, 2, 2, 3, 1, 1, 0, 2, 1, 2, 1, 0, 0, 1, 2, 1, 2, 2, 2, 1, 2, 1,\n",
      "        1, 3, 1, 3, 2, 2, 3, 2, 2, 2, 2, 3, 2, 3, 0, 3, 0, 2, 2, 0, 1, 1, 0, 0,\n",
      "        0, 2, 2, 3, 2, 3, 2, 0, 3, 3, 0, 3, 1, 2, 0, 2, 3, 1, 3, 2, 0, 1, 0, 3,\n",
      "        2, 0, 1, 3, 1, 2, 2, 1, 1, 3, 2, 0, 0, 1, 1, 2, 0, 0, 1, 0, 1, 0, 0, 2,\n",
      "        0, 3, 2, 3, 0, 2, 3, 1, 2, 0, 1, 1, 3, 2, 0, 3, 1, 1, 3, 2, 3, 2, 1, 3,\n",
      "        1, 2, 1, 1, 0, 2, 2, 3, 2, 3, 0, 2, 2, 1, 2, 3, 1, 1, 2, 0, 2, 0, 3, 0,\n",
      "        0, 0, 2, 2, 3, 1, 3, 1, 1, 2, 2, 1, 1, 0, 3, 2, 1, 3, 3, 0, 1, 3, 2, 0,\n",
      "        2, 2, 2, 1, 0, 1, 2, 2, 3, 1, 1, 2, 2, 2, 2, 2])\n",
      "torch.Size([256])\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1be1975f",
    "outputId": "6ac30aca-7b5f-4f34-86c6-c13c1ff767d3",
    "ExecuteTime": {
     "end_time": "2025-10-26T06:46:01.091365Z",
     "start_time": "2025-10-26T06:35:05.845035Z"
    }
   },
   "source": [
    "model = DNACoder(input_dim=4, window_size=window_size).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "for epoch in range(40):\n",
    "    total_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    model.train()\n",
    "    for xb, yb in loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(xb.float())\n",
    "        loss = criterion(outputs, yb)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "        preds = torch.argmax(outputs, dim=1)   # predicted class index\n",
    "        correct += (preds == yb).sum().item()\n",
    "        total += yb.size(0)\n",
    "\n",
    "    epoch_loss = total_loss / len(loader)\n",
    "    epoch_acc = correct / total * 100\n",
    "    if epoch % 5 == 0:\n",
    "        print(f\"Epoch [{epoch+1}/40], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[21], line 17\u001B[0m\n\u001B[0;32m     15\u001B[0m outputs \u001B[38;5;241m=\u001B[39m model(xb\u001B[38;5;241m.\u001B[39mfloat())\n\u001B[0;32m     16\u001B[0m loss \u001B[38;5;241m=\u001B[39m criterion(outputs, yb)\n\u001B[1;32m---> 17\u001B[0m \u001B[43mloss\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m optimizer\u001B[38;5;241m.\u001B[39mstep()\n\u001B[0;32m     20\u001B[0m total_loss \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m loss\u001B[38;5;241m.\u001B[39mitem()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\_tensor.py:626\u001B[0m, in \u001B[0;36mTensor.backward\u001B[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001B[0m\n\u001B[0;32m    616\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m has_torch_function_unary(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    617\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m handle_torch_function(\n\u001B[0;32m    618\u001B[0m         Tensor\u001B[38;5;241m.\u001B[39mbackward,\n\u001B[0;32m    619\u001B[0m         (\u001B[38;5;28mself\u001B[39m,),\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    624\u001B[0m         inputs\u001B[38;5;241m=\u001B[39minputs,\n\u001B[0;32m    625\u001B[0m     )\n\u001B[1;32m--> 626\u001B[0m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mautograd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mbackward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    627\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mgradient\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43minputs\u001B[49m\n\u001B[0;32m    628\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\__init__.py:347\u001B[0m, in \u001B[0;36mbackward\u001B[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001B[0m\n\u001B[0;32m    342\u001B[0m     retain_graph \u001B[38;5;241m=\u001B[39m create_graph\n\u001B[0;32m    344\u001B[0m \u001B[38;5;66;03m# The reason we repeat the same comment below is that\u001B[39;00m\n\u001B[0;32m    345\u001B[0m \u001B[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001B[39;00m\n\u001B[0;32m    346\u001B[0m \u001B[38;5;66;03m# calls in the traceback and some print out the last line\u001B[39;00m\n\u001B[1;32m--> 347\u001B[0m \u001B[43m_engine_run_backward\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    348\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtensors\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    349\u001B[0m \u001B[43m    \u001B[49m\u001B[43mgrad_tensors_\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    350\u001B[0m \u001B[43m    \u001B[49m\u001B[43mretain_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    351\u001B[0m \u001B[43m    \u001B[49m\u001B[43mcreate_graph\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    352\u001B[0m \u001B[43m    \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    353\u001B[0m \u001B[43m    \u001B[49m\u001B[43mallow_unreachable\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    354\u001B[0m \u001B[43m    \u001B[49m\u001B[43maccumulate_grad\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[0;32m    355\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\torch\\autograd\\graph.py:823\u001B[0m, in \u001B[0;36m_engine_run_backward\u001B[1;34m(t_outputs, *args, **kwargs)\u001B[0m\n\u001B[0;32m    821\u001B[0m     unregister_hooks \u001B[38;5;241m=\u001B[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001B[0;32m    822\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 823\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mVariable\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_execution_engine\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrun_backward\u001B[49m\u001B[43m(\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001B[39;49;00m\n\u001B[0;32m    824\u001B[0m \u001B[43m        \u001B[49m\u001B[43mt_outputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\n\u001B[0;32m    825\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001B[39;00m\n\u001B[0;32m    826\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    827\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m attach_logging_hooks:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uu8URO2aakMe"
   },
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "74fef23c",
    "outputId": "71dcffd1-e631-4c10-cc81-3a4438521250"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "loaded_model = DNACoder(input_dim=4, window_size=window_size).to(device)\n",
    "loaded_model.load_state_dict(torch.load('model.pth'))\n",
    "loaded_model.eval()\n",
    "\n",
    "print(\"Model loaded successfully!\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
