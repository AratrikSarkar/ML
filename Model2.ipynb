{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 543,
     "status": "ok",
     "timestamp": 1760191090735,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "vK310gA8Bvdc",
    "outputId": "81f7f7f2-2267-406f-8b5e-0eb0436bf605"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7b6bfc0f0af0>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import init\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "torch.manual_seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 1126,
     "status": "ok",
     "timestamp": 1760191092406,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "13e8b162"
   },
   "outputs": [],
   "source": [
    "with open(\"/content/AeCa\",'r',encoding='UTF-8') as f:\n",
    "    text=f.read()\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1760191092406,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "3vox1PTWAjOJ",
    "outputId": "405be536-4a3e-40b4-fc17-906462f45ea0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['A', 'C', 'G', 'T'] 4\n"
     ]
    }
   ],
   "source": [
    "chars=sorted(list(set(text)))\n",
    "vocab_size=len(chars)\n",
    "print(chars,vocab_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1760191092406,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "YQT3V5F1FRka",
    "outputId": "3b10cb83-4ad0-4259-9c2a-ee52bbdc5507"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'A': 0, 'C': 1, 'G': 2, 'T': 3}, {0: 'A', 1: 'C', 2: 'G', 3: 'T'})"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi={s:i for i,s in enumerate(chars)}\n",
    "itos={i:s for i,s in enumerate(stoi)}\n",
    "stoi,itos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1760191092406,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "dLLH17xCBmMK"
   },
   "outputs": [],
   "source": [
    "encode=lambda word:[stoi[s] for s in word]\n",
    "decode=lambda num: ''.join([itos[i] for i in num])\n",
    "data=torch.tensor(encode(text),dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1760191092406,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "BVCnWBApGi0m",
    "outputId": "c8b84959-2812-40d6-ed3c-5d5d3419d7d2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1,  ..., 2, 2, 1])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1760191092406,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "VyP_fdiFdi4D",
    "outputId": "21f20f2c-5b1e-4d44-c34b-05370d1be48f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1272839]) torch.Size([159105]) torch.Size([159105])\n"
     ]
    }
   ],
   "source": [
    "l=int(0.8*data.shape[0])\n",
    "h=int(0.9*data.shape[0])\n",
    "train_data=data[:l]\n",
    "val_data=data[l:h]\n",
    "test_data=data[h:]\n",
    "print(train_data.shape,val_data.shape,test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1760191092406,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "b-3pbDGddzgt",
    "outputId": "29d26198-17a0-4316-a34a-88064614c814"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 1, 1, 2, 1, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "block_size=8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1760191092406,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "6yX6eBrad7JQ",
    "outputId": "87d6773a-9a40-4822-a762-c4da216cad87"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In the context of tensor([2]) the target is 1\n",
      "In the context of tensor([2, 1]) the target is 1\n",
      "In the context of tensor([2, 1, 1]) the target is 2\n",
      "In the context of tensor([2, 1, 1, 2]) the target is 1\n",
      "In the context of tensor([2, 1, 1, 2, 1]) the target is 1\n",
      "In the context of tensor([2, 1, 1, 2, 1, 1]) the target is 1\n",
      "In the context of tensor([2, 1, 1, 2, 1, 1, 1]) the target is 1\n",
      "In the context of tensor([2, 1, 1, 2, 1, 1, 1, 1]) the target is 1\n"
     ]
    }
   ],
   "source": [
    "x=train_data[:block_size]\n",
    "y=train_data[1:block_size+1]\n",
    "for t in range (block_size):\n",
    "    context=x[:t+1]\n",
    "    target=y[t]\n",
    "    print(f\"In the context of {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1760191092407,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "r5sabuBkG6p_"
   },
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(self,fan_in,fan_out,bias=False):\n",
    "        super().__init__()\n",
    "        self.W=nn.Parameter(torch.randn((fan_out,fan_in)))\n",
    "        self.b=nn.Parameter(torch.randn(fan_out)) if bias==True else None\n",
    "        init.kaiming_uniform_(self.W, nonlinearity='relu')\n",
    "\n",
    "        # 3. Initialize Bias (if used) to zero, as is standard practice\n",
    "        if self.b is not None:\n",
    "            init.zeros_(self.b)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out= x @ self.W.T\n",
    "        if self.b is not None:\n",
    "            out=out+self.b\n",
    "        return  out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1760191092407,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "I-qw03hseGSt"
   },
   "outputs": [],
   "source": [
    "class ReLu(nn.Module):\n",
    "    def __init__(self,inplace=False):\n",
    "        super().__init__()\n",
    "        self.inplace=inplace\n",
    "\n",
    "    def forward(self,x):\n",
    "        if(self.inplace):\n",
    "            return torch.clamp_(x,min=0.0)      # modifies x\n",
    "        else:\n",
    "            return torch.clamp(x,min=0.0)       # x remains unchanged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1760191092407,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "Jh1aNF1xeJWD"
   },
   "outputs": [],
   "source": [
    "class Sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out=torch.empty_like(x)\n",
    "        positive=x>=0\n",
    "        negative=~positive\n",
    "        out[positive]=1/(1+torch.exp(-x[positive]))\n",
    "        exp_x=torch.exp(x[negative])\n",
    "        out[negative]=exp_x/(1+exp_x)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1760191092407,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "h8b5AUiWeMB6"
   },
   "outputs": [],
   "source": [
    "class TanH(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "    def forward(self,x):\n",
    "        out=torch.empty_like(x)\n",
    "        positive=x>=0\n",
    "        negative=~positive\n",
    "        out[positive]=1-(2/(torch.exp(2*x[positive])+1))\n",
    "        out[negative]=(2/(torch.exp(-2*x[negative])+1))-1\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1760191092407,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "rxH08C5gHXhZ"
   },
   "outputs": [],
   "source": [
    "class Dropout(nn.Module):\n",
    "    def __init__(self, p=0.5, inplace=False):\n",
    "        super().__init__()\n",
    "        if p < 0 or p > 1:\n",
    "            raise ValueError(\"Dropout probability must be between 0 and 1.\")\n",
    "        self.p = p  # probability of dropping a unit\n",
    "        self.inplace = inplace\n",
    "\n",
    "    def forward(self, x):\n",
    "        if not self.training or self.p == 0.0:\n",
    "            return x\n",
    "\n",
    "        # Create a mask: 1 for keep, 0 for drop\n",
    "        mask = (torch.rand_like(x) > self.p).float()\n",
    "\n",
    "        if self.inplace:\n",
    "            x.mul_(mask).div_(1 - self.p)  # scale to keep expected value\n",
    "            out = x\n",
    "        else:\n",
    "            out = (x * mask) / (1 - self.p)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1760191092407,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "5N56ofC3IGKO"
   },
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, bias=True, batch_first=False,only_output=False):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.batch_first = batch_first\n",
    "        self.only_output= only_output\n",
    "\n",
    "        # Input → Gates\n",
    "        self.x2i = Linear(input_size, hidden_size, bias)  # input gate\n",
    "        self.x2f = Linear(input_size, hidden_size, bias)  # forget gate\n",
    "        self.x2o = Linear(input_size, hidden_size, bias)  # output gate\n",
    "        self.x2g = Linear(input_size, hidden_size, bias)  # candidate cell state\n",
    "\n",
    "        # Hidden → Gates\n",
    "        self.h2i = Linear(hidden_size, hidden_size, bias)\n",
    "        self.h2f = Linear(hidden_size, hidden_size, bias)\n",
    "        self.h2o = Linear(hidden_size, hidden_size, bias)\n",
    "        self.h2g = Linear(hidden_size, hidden_size, bias)\n",
    "\n",
    "        # Activations\n",
    "        self.sigmoid = Sigmoid()\n",
    "        self.tanh = TanH()\n",
    "\n",
    "    def forward(self, x, state=None):\n",
    "        \"\"\"\n",
    "        x: (seq_len, batch_size, input_size) or (batch_size, seq_len, input_size)\n",
    "        state: tuple (h0, c0)\n",
    "               h0: (batch_size, hidden_size)\n",
    "               c0: (batch_size, hidden_size)\n",
    "        \"\"\"\n",
    "        if self.batch_first:\n",
    "            x = x.permute(1, 0, 2)  # to (seq_len, batch_size, input_size)\n",
    "\n",
    "        seq_len, batch_size, _ = x.shape\n",
    "\n",
    "        # h_t : Hidden State (Short Term Memory)\n",
    "        # c_t : Cell State (Long Term Memory)\n",
    "\n",
    "        if state is None:\n",
    "            h_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "            c_t = torch.zeros(batch_size, self.hidden_size, device=x.device)\n",
    "        else:\n",
    "            h_t, c_t = state\n",
    "\n",
    "        outputs = torch.zeros(seq_len, batch_size, self.hidden_size, device=x.device)\n",
    "\n",
    "        for t in range(seq_len):\n",
    "            x_t = x[t]\n",
    "\n",
    "            # Gates\n",
    "            i_t = self.sigmoid(self.x2i(x_t) + self.h2i(h_t))   # input gate\n",
    "            f_t = self.sigmoid(self.x2f(x_t) + self.h2f(h_t))   # forget gate\n",
    "            o_t = self.sigmoid(self.x2o(x_t) + self.h2o(h_t))   # output gate\n",
    "            g_t = self.tanh(self.x2g(x_t) + self.h2g(h_t))      # candidate cell state\n",
    "\n",
    "            # Cell state update\n",
    "            c_t = f_t * c_t + i_t * g_t\n",
    "\n",
    "            # Hidden state update\n",
    "            h_t = o_t * self.tanh(c_t)\n",
    "\n",
    "            outputs[t] = h_t\n",
    "\n",
    "        if self.batch_first:\n",
    "            outputs = outputs.permute(1, 0, 2)\n",
    "        if self.only_output:\n",
    "            return outputs\n",
    "        return outputs, (h_t.unsqueeze(0), c_t.unsqueeze(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1760191092407,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "FwYxeq3kJcqp"
   },
   "outputs": [],
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    def __init__(self, normalized_shape, eps=1e-5):\n",
    "        super().__init__()\n",
    "        if isinstance(normalized_shape, int):\n",
    "            normalized_shape = (normalized_shape,)\n",
    "        self.normalized_shape = tuple(normalized_shape)\n",
    "        self.eps = eps\n",
    "\n",
    "        # Learnable params\n",
    "        self.gamma = nn.Parameter(torch.ones(self.normalized_shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(self.normalized_shape))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Normalize across last len(normalized_shape) dims\n",
    "        dims = tuple(range(-len(self.normalized_shape), 0))\n",
    "        mean = x.mean(dim=dims, keepdim=True)\n",
    "        var = x.var(dim=dims, unbiased=False, keepdim=True)\n",
    "\n",
    "        x_hat = (x - mean) / torch.sqrt(var + self.eps)\n",
    "        out = self.gamma * x_hat + self.beta\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1760191092407,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "SyAQp_7-fnEx"
   },
   "outputs": [],
   "source": [
    "class Softmax(nn.Module):\n",
    "    def __init__(self, dim=-1):\n",
    "        super().__init__()\n",
    "        self.dim = dim  # dimension over which to apply softmax\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Numerical stability: subtract max value along dim before exponentiating\n",
    "        x_max, _ = torch.max(x, dim=self.dim, keepdim=True)\n",
    "        x_exp = torch.exp(x - x_max)\n",
    "        out = x_exp / torch.sum(x_exp, dim=self.dim, keepdim=True)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1760191092407,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "aYrZ0UDPIg1t"
   },
   "outputs": [],
   "source": [
    "class Head(nn.Module):\n",
    "    \"\"\" a single self attention head \"\"\"\n",
    "\n",
    "    def __init__(self, n_embd, head_size, block_size,bias=False,only_output=False):\n",
    "        super().__init__()\n",
    "        self.key=Linear(n_embd,head_size,bias)\n",
    "        self.query=Linear(n_embd,head_size,bias)\n",
    "        self.value=Linear(n_embd,head_size,bias)\n",
    "        self.register_buffer('tril',torch.tril(torch.ones(block_size,block_size)))\n",
    "        self.dropout=Dropout().to(device=device)\n",
    "        self.softmax=Softmax(dim=-1)\n",
    "        self.only_output=only_output\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        B,T,C = x.shape\n",
    "        k = self.key(x)       # (B,T,hs)\n",
    "        q = self.query(x)     # (B,T,hs)\n",
    "\n",
    "        # compute attention scores (\"affinities\")\n",
    "        wei = q @ k.transpose(-2,-1)*C**(-0.5)                               #(B,T,C) @ (B,C,T) --------> (B,T,T)\n",
    "        wei = wei.masked_fill(self.tril[:T,:T] == 0, float('-inf'))         #(B,T,T)\n",
    "        wei = self.softmax(wei)                                        #(B,T,T)\n",
    "        wei = self.dropout(wei)\n",
    "\n",
    "        # perform the weighted aggregation of the values\n",
    "        v = self.value(x)\n",
    "        out = wei @ v\n",
    "\n",
    "        if self.only_output:\n",
    "            return out\n",
    "\n",
    "        return out,wei\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
    "\n",
    "    def __init__(self,num_head,n_embd, head_size, block_size,bias=False):\n",
    "        super().__init__()\n",
    "        self.heads=nn.ModuleList([Head(n_embd, head_size, block_size,bias=False) for _ in range(num_head)])\n",
    "        self.proj=Linear(n_embd,n_embd)\n",
    "        self.dropout = Dropout()\n",
    "\n",
    "    def forward(self,x):\n",
    "        j=[h(x) for h in self.heads]\n",
    "        # print(len(j),len(j[0]))\n",
    "        out=torch.cat([h(x)[0] for h in self.heads],dim=-1)\n",
    "        out=self.dropout(self.proj(out))\n",
    "        #print(out.shape)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "executionInfo": {
     "elapsed": 586,
     "status": "ok",
     "timestamp": 1760191139115,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "rq_7LZdRYvHL"
   },
   "outputs": [],
   "source": [
    "block_size=32\n",
    "batch_size = 64\n",
    "n_embd = 64\n",
    "hidden_size=4*n_embd\n",
    "n_head = 8\n",
    "eval_interval=20\n",
    "max_iters=100\n",
    "learning_rate = 0.001\n",
    "eval_iters = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 814,
     "status": "ok",
     "timestamp": 1760191673250,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "J3-EO7S3IxE0"
   },
   "outputs": [],
   "source": [
    "from posixpath import pardir\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class M2(nn.Module):\n",
    "    def __init__(self,block_size,vocab_size,n_embd,hidden_size,n_head):\n",
    "        super().__init__()\n",
    "        self.token_embedding_table=nn.Embedding(vocab_size,n_embd)\n",
    "        head_size=n_embd//2\n",
    "        self.net=nn.Sequential(\n",
    "            Linear(n_embd,4*n_embd),    #per token level,all tokens do this independently\n",
    "            ReLu(),\n",
    "            Dropout(0.3),\n",
    "            LSTM(4*n_embd,n_embd,batch_first=True,only_output=True), #only_output=True\n",
    "            LayerNorm(n_embd),\n",
    "            Head( n_embd, head_size, block_size,only_output=True),\n",
    "            LayerNorm(block_size),\n",
    "            Linear(block_size,vocab_size)\n",
    "\n",
    "        )\n",
    "\n",
    "    def forward(self,x,targets=None):\n",
    "        p=self.token_embedding_table(x)\n",
    "        logits= self.net(p)\n",
    "\n",
    "        #print(logits.shape)\n",
    "\n",
    "\n",
    "        if targets is None:\n",
    "            loss = None\n",
    "        else:\n",
    "            B,T,C=logits.shape\n",
    "            logits=logits.view(B*T,C)\n",
    "            targets=targets.view(B*T)\n",
    "            loss=F.cross_entropy(logits,targets)#as it takes input as (B,C,T)\n",
    "\n",
    "        return logits,loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1760191681682,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "52z9ajJ3SQB8",
    "outputId": "8c0bc4f1-30b0-4b9f-a3ad-e58d790faf09"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 32]) torch.Size([64, 32])\n",
      "torch.Size([64, 32, 4])\n"
     ]
    }
   ],
   "source": [
    "def get_batch(split):\n",
    "    #generate a small batch of data of inputs x and target y\n",
    "    data =train_data if split=='train' else val_data\n",
    "    ix= torch.randint(len(data)-block_size,(batch_size,))  # if len(data) is 10 we cannot find a chunck of size 9 after index 1\n",
    "    #print(ix)\n",
    "    x=torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y=torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    x,y=x.to(device),y.to(device)\n",
    "    return x,y\n",
    "\n",
    "x,y=get_batch('train')\n",
    "x = x.to(device)\n",
    "y = y.to(device)\n",
    "print(x.shape,y.shape)\n",
    "model=M2(block_size,vocab_size,n_embd,hidden_size,n_head)\n",
    "model=model.to(device)\n",
    "z=model(x)\n",
    "print(z[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 125933,
     "status": "ok",
     "timestamp": 1760191269805,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "YP3XBmDkSiU2",
    "outputId": "def3ad41-c755-4990-e9cb-e0cbc49b1485"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step 0: train loss 1.4230, val loss 1.4250\n",
      "step 20: train loss 1.3674, val loss 1.3671\n",
      "step 40: train loss 1.3624, val loss 1.3621\n",
      "step 60: train loss 1.3638, val loss 1.3609\n",
      "step 80: train loss 1.3600, val loss 1.3601\n",
      "step 99: train loss 1.3599, val loss 1.3572\n"
     ]
    }
   ],
   "source": [
    "def estimate_loss():\n",
    "    out={}\n",
    "    model.eval()\n",
    "    for split in ['train','val']:\n",
    "        losses=torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X,Y=get_batch(split)\n",
    "            logits,loss=model(X,Y)\n",
    "            losses[k]=loss.item()\n",
    "        out[split]=losses.mean()\n",
    "    model.train()\n",
    "    return out\n",
    "\n",
    "\n",
    "optimizer=torch.optim.Adam(model.parameters(),learning_rate)\n",
    "for iter in range(max_iters):\n",
    "\n",
    "    # every once in a while evaluate the loss on train and val sets\n",
    "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
    "        losses = estimate_loss()\n",
    "        print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
    "\n",
    "    # sample a batch of data\n",
    "    xb, yb = get_batch('train')\n",
    "    #print(xb.shape,yb.shape)\n",
    "\n",
    "    # evaluate the loss\n",
    "    logits, loss = model(xb, yb)\n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1760191104832,
     "user": {
      "displayName": "Arnab Chakraborty",
      "userId": "02220918150251638366"
     },
     "user_tz": -330
    },
    "id": "Uju8HeKyjXKV"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyO70moATO9ONBIfjyheTWDg",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
